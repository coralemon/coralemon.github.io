---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>


I am currently a PHD student in 4DVLab, ShanghaiTech University, supervised by Prof. <a href='https://yuexinma.me/index.html'>Yuexin Ma</a>. My research focuses on human-centric scene understanding, multi-modal inputs, thereby enabling embodied planning and physical interactions. In recent years, we have contributed several fundamental endeavors in general 3D perception from LiDAR point clouds, monocular images and videos with an open-source codebase, MMDetection3D.

My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICME 2021</div><img src='images/icme1.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Input-output balanced framework for long-tailed lidar semantic segmentation](https://arxiv.org/pdf/2103.14269)

**Peishan Cong**, Xinge Zhu, Yuexin Ma.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2022</div><img src='images/stcrowd.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Stcrowd: A multimodal dataset for pedestrian perception in crowded scenes.](https://openaccess.thecvf.com/content/CVPR2022/papers/Cong_STCrowd_A_Multimodal_Dataset_for_Pedestrian_Perception_in_Crowded_Scenes_CVPR_2022_paper.pdf)

**Peishan Cong**, Xinge Zhu, Feng Qiao, Yiming Ren, Xidong Peng, Yuenan Hou, Lan Xu, Ruigang Yang, Dinesh Manocha, Yuexin Ma.¬†
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICME 2022</div><img src='images/icme2022.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Self-Supervised Point Cloud Completion on Real Traffic Scenes Via Scene-Concerned Bottom-Up Mechanism.](https://arxiv.org/pdf/2203.10569)

Yiming Ren, **Peishan Cong**, Xinge Zhu, Yuexin Ma.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TVCG 2023</div><img src='images/Lip.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Lidar-aid inertial poser: Large-scale human motion capture by sparse inertial and lidar sensors.](https://arxiv.org/pdf/2205.15410)

Yiming Ren*, Chengfeng Zhao*, Yannan He, **Peishan Cong**, Han Liang, Jingyi Yu, Lan Xu, Yuexin Ma.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2023</div><img src='images/fusionpose' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Weakly Supervised 3D Multi-person Pose Estimation for Large-scale Scenes based on Monocular Camera and Single LiDAR.](https://arxiv.org/pdf/2205.15410)

**Peishan Cong**, Yiteng Xu*, Yiming Ren, Juze Zhang, Lan Xu, Jingya Wang, Jingyi Yu, Yuexin Ma. 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/hucenlife.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Lidar-aid inertial poser: Large-scale human motion capture by sparse inertial and lidar sensors.](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Human-centric_Scene_Understanding_for_3D_Large-scale_Scenarios_ICCV_2023_paper.pdf)

Yiteng Xu*,**Peishan Cong** *,Yichen Yao*, Runnan Chen, Yuenan Hou, Xinge Zhu, Xuming He, Jingyi Yu,Yuexin Ma. Human-centric Scene Understanding in 3D Large-scale Scenarios. 
</div>
</div>

# üéñ Honors and Awards
- *2022.10, 2023.10* Merit Student
- *2021.06* Outstanding graduate Student , Shanghai
- *2020.02* Outstanding Teacher Assistant Award, ShanghaiTech University
- *2019.10* Third Prize Scholarship, ShanghaiTech University
- *2019.9* Outstanding Student Award, ShanghaiTech University	

# üìñ Educations
- *2021.09 - present *, PHD, ShanghaiTech University, Shanghai, China.
- *2017.09 - 2021.07 *, Bachelor, ShanghaiTech University, Shanghai, China.

# üí¨ Teaching Assistants
- ShanghaiTech University, 2019.10 - 2022.12
  - Computer Graphic (Spring 2022,Fall 2022).
  - Algorithms and Analysis (Fall 2021).
  - Optimization and Machine learning (Spring 2020).
  - Algorithms and AnalysisDatabase and Data mining (Fall 2019).
- Utech Academy, 2021.06
  - Machine learning

# üíª Internships
- *2024.05 - present*, [MMLab](http://mmlab.ie.cuhk.edu.hk), Hongkong, China.
- *2021.12 - 2022.05*, [Shanghai AI Lab](https://www.shlab.org.cn), Shanghai, China.
